{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "import biosppy\n",
    "import h5pickle as h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hdf = h5py.File('./input/train_dccweek2023.h5', 'r')\n",
    "test_hdf = h5py.File('./input/test_dccweek2023.h5', 'r')\n",
    "\n",
    "train_labels = pd.read_csv('./input/train_dccweek2023-labels.csv')\n",
    "train_labels.columns = ['ids', 'classes']\n",
    "ecg_types = ['DI', 'DII', 'DIII', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "ecg_types_dict = {'DI': 0, 'DII': 1, 'DIII': 2, 'AVR': 3, 'AVL': 4, 'AVF': 5, 'V1': 6, 'V2': 7, 'V3': 8, 'V4': 9, 'V5': 10, 'V6': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_stats(x, preffix=''):\n",
    "    stats = {}\n",
    "    stats['avg'] = np.mean(x)\n",
    "    stats['std'] = np.std(x)\n",
    "    stats['var'] = np.var(x)\n",
    "    stats['min'] = np.min(x)\n",
    "    stats['max'] = np.max(x)\n",
    "    stats['q25'] = np.quantile(x, .25)\n",
    "    stats['q50'] = np.quantile(x, .50)\n",
    "    stats['q75'] = np.quantile(x, .75)\n",
    "    # stats['count'] = len(x)\n",
    "    # stats['nunique'] = len(np.unique(x))\n",
    "    # stats['kurt'] = kurtosis(x)\n",
    "    # stats['skew'] = skew(x)\n",
    "    stats = {preffix+k: v for k, v in stats.items()} # Add preffix\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hdf(hdf):\n",
    "    train_ids = np.array(hdf['exam_id'])\n",
    "    tracings = hdf['tracings']\n",
    "    features_list = []\n",
    "    #for id in tqdm(range(len(train_ids))):\n",
    "    for id in tqdm(range(100)):\n",
    "        features = {'exam_id': train_ids[id]}\n",
    "        for ecg in range(len(ecg_types)):\n",
    "            values = np.array(tracings[id, :, ecg])\n",
    "            try:\n",
    "                ts, filtered, rpeaks, template_ts, templates, hear_rate_ts, heart_rate = biosppy.signals.ecg.ecg(values, sampling_rate=400, show=False)\n",
    "                diff_templates = np.diff(templates)\n",
    "                diff_heart_rate = np.diff(heart_rate)\n",
    "                raw_to_filtered_diff = values - filtered\n",
    "                features.update(features_stats(raw_to_filtered_diff, preffix=f'{ecg_types[ecg]}_raw_diff_'))\n",
    "                features.update(features_stats(filtered, preffix=f'{ecg_types[ecg]}_'))\n",
    "                features.update(features_stats(filtered[rpeaks], preffix=f'{ecg_types[ecg]}_peaks_'))\n",
    "                features.update(features_stats(heart_rate, preffix=f'{ecg_types[ecg]}_heart_rate_'))\n",
    "                features.update(features_stats(diff_heart_rate, preffix=f'{ecg_types[ecg]}_heart_rate_diff'))\n",
    "                features.update(features_stats(templates.mean(axis=0), preffix=f'{ecg_types[ecg]}_templates_'))\n",
    "                features.update(features_stats(templates.std(axis=0), preffix=f'{ecg_types[ecg]}_templates_std_'))\n",
    "                features.update(features_stats(diff_templates.mean(axis=0), preffix=f'{ecg_types[ecg]}_templates_diff_'))\n",
    "                features.update(features_stats(diff_templates.std(axis=0), preffix=f'{ecg_types[ecg]}_templates_std_diff_'))\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                pass    \n",
    "        features_list.append(features)        \n",
    "    return pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = process_hdf(train_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = process_hdf(test_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./input/v1processed_train.csv', index=False)\n",
    "test_df.to_csv('./input/v1processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(template):    \n",
    "    r_peak = np.argmax(template)    \n",
    "    q_peak = np.argmin(template[:r_peak])    \n",
    "    s_peak = np.argmin(template[r_peak:]) + len(template[:r_peak])    \n",
    "    p_peak = np.argmax(template[:q_peak])    \n",
    "    t_peak = np.argmax(template[s_peak:]) + len(template[:s_peak])\n",
    "    return r_peak, q_peak, s_peak, p_peak, t_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import scipy\n",
    "\n",
    "def frequency_domain_features(signal, fs=400, low_freq_band=[4, 15], high_freq_band=[15, 40], very_low_freq_band=[0, 4]):\n",
    "    # Calculate power spectral density\n",
    "    freqs, psd = scipy.signal.welch(signal, fs)\n",
    "    # Calculate spectral power in different frequency bands\n",
    "    lf_power = np.trapz(psd[(freqs >= low_freq_band[0]) & (freqs <= low_freq_band[1])])\n",
    "    hf_power = np.trapz(psd[(freqs >= high_freq_band[0]) & (freqs <= high_freq_band[1])])\n",
    "    vlf_power = np.trapz(psd[(freqs >= very_low_freq_band[0]) & (freqs <= very_low_freq_band[1])])\n",
    "    # Calculate spectral centroid, bandwidth, and entropy\n",
    "    spectral_centroid = np.sum(freqs * psd) / np.sum(psd)\n",
    "    spectral_bandwidth = np.sqrt(np.sum(psd * (freqs - spectral_centroid)**2) / np.sum(psd))\n",
    "    spectral_entropy = -np.sum(psd * np.log2(psd))\n",
    "    # Calculate wavelet transform coefficients\n",
    "    coeffs = pywt.wavedec(signal, wavelet='db4', level=6)\n",
    "    # Extract wavelet transform features\n",
    "    cA6, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
    "    energy = [np.sum(np.square(cA6)), np.sum(np.square(cD6)), np.sum(np.square(cD5)),\n",
    "              np.sum(np.square(cD4)), np.sum(np.square(cD3)), np.sum(np.square(cD2)), np.sum(np.square(cD1))]\n",
    "    std = [np.std(cA6), np.std(cD6), np.std(cD5), np.std(cD4), np.std(cD3), np.std(cD2), np.std(cD1)]\n",
    "    return lf_power, hf_power, vlf_power, spectral_centroid, spectral_bandwidth, spectral_entropy, energy, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(hdf, sample=None):\n",
    "    # Open file\n",
    "    f = hdf\n",
    "    traces_ids = np.array(f['exam_id'])\n",
    "    X = f['tracings']\n",
    "    # Get Dimensions\n",
    "    num_samples = X.shape[0] if sample is None else sample\n",
    "    num_leads = X.shape[2]\n",
    "    \n",
    "    features_list = []\n",
    "    for i in tqdm(range(num_samples)):        \n",
    "        ecg_data = X[i, :, :]\n",
    "        features = {'exam_id': traces_ids[i]}\n",
    "        for j in range(num_leads):\n",
    "            # Filter signal padding\n",
    "            ecg_signal = np.trim_zeros(ecg_data[:, j])\n",
    "            try:\n",
    "                ts, filtered, rpeaks, template_ts, templates, hear_rate_ts, heart_rate = biosppy.signals.ecg.ecg(\n",
    "                    ecg_signal, sampling_rate=400, show=False\n",
    "                )\n",
    "            except:\n",
    "                pass      \n",
    "            ######################################## Time-Domain Features ########################################            \n",
    "            # Calculate time intervals between consecutive R-peaks (in samples)\n",
    "            rr_intervals = np.diff(rpeaks)            \n",
    "            # Convert time intervals to seconds\n",
    "            rr_intervals_sec = rr_intervals / 400.0\n",
    "            # Compute heart rate (in BPM)\n",
    "            hr = 60.0 / rr_intervals_sec\n",
    "            # Compute average heart rate over a specific period (e.g., 1 minute)\n",
    "            average_hr = np.mean(hr)\n",
    "            features[f'lead{j}_average_hr'] = average_hr\n",
    "            # Average RR-Interval\n",
    "            features[f'lead{j}_average_rr_interval'] = np.mean(rr_intervals)\n",
    "            # Other intervals\n",
    "            pr_intervals = []\n",
    "            qrs_durations = []\n",
    "            qt_intervals = []\n",
    "            for template in templates:\n",
    "                if template.max() < np.abs(template.min()):\n",
    "                    template = -template\n",
    "                try:\n",
    "                    r_peak, q_peak, s_peak, p_peak, t_peak = find_peaks(template)\n",
    "                    pr_intervals.append(q_peak - p_peak)\n",
    "                    qrs_durations.append(s_peak - q_peak)\n",
    "                    qt_intervals.append(t_peak - q_peak)\n",
    "                except:\n",
    "                    pass\n",
    "            features[f'lead{j}_average_pr_interval'] = np.mean(pr_intervals)\n",
    "            features[f'lead{j}_average_qrs_durations'] = np.mean(qrs_durations)\n",
    "            features[f'lead{j}_average_qt_interval'] = np.mean(qt_intervals)\n",
    "            ######################################## Frequency-Domain Features ########################################\n",
    "            lf_power, hf_power, vlf_power, spectral_centroid, spectral_bandwidth, spectral_entropy, energy, std = frequency_domain_features(filtered)\n",
    "            features[f'lead{j}_lf_power'] = lf_power\n",
    "            features[f'lead{j}_hf_power'] = hf_power\n",
    "            features[f'lead{j}_vlf_power'] = vlf_power\n",
    "            features[f'lead{j}_spectral_centroid'] = spectral_centroid\n",
    "            features[f'lead{j}_spectral_bandwidth'] = spectral_bandwidth\n",
    "            features[f'lead{j}_spectral_entropy'] = spectral_entropy\n",
    "            features[f'lead{j}_average_energy'] = np.mean(energy)\n",
    "            features[f'lead{j}_average_std'] = np.mean(std)\n",
    "        features_list.append(features)        \n",
    "    return pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_features(train_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process_features(test_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./input/v2processed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./input/v2processed_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03244324ea5ab45df864bf71cde3f5c18aba38ee2199e9c7a316a8540f6573f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
