{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('./input/train_dccweek2023-labels.csv')\n",
    "train_labels.columns = ['exam_id', 'classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./input/v1processed_train.csv')\n",
    "test_df = pd.read_csv('./input/v1processed_test.csv')\n",
    "\n",
    "train_df2 = pd.read_csv('./input/v2processed_train.csv')\n",
    "test_df2 = pd.read_csv('./input/v2processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, train_df2, on='exam_id', how='left')\n",
    "test_df = pd.merge(test_df, test_df2, on='exam_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_id</th>\n",
       "      <th>DI_raw_diff_avg</th>\n",
       "      <th>DI_raw_diff_std</th>\n",
       "      <th>DI_raw_diff_var</th>\n",
       "      <th>DI_raw_diff_min</th>\n",
       "      <th>DI_raw_diff_max</th>\n",
       "      <th>DI_raw_diff_q25</th>\n",
       "      <th>DI_raw_diff_q50</th>\n",
       "      <th>DI_raw_diff_q75</th>\n",
       "      <th>DI_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>lead11_average_qrs_durations</th>\n",
       "      <th>lead11_average_qt_interval</th>\n",
       "      <th>lead11_lf_power</th>\n",
       "      <th>lead11_hf_power</th>\n",
       "      <th>lead11_vlf_power</th>\n",
       "      <th>lead11_spectral_centroid</th>\n",
       "      <th>lead11_spectral_bandwidth</th>\n",
       "      <th>lead11_spectral_entropy</th>\n",
       "      <th>lead11_average_energy</th>\n",
       "      <th>lead11_average_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3123252</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>0.147280</td>\n",
       "      <td>0.021691</td>\n",
       "      <td>-0.168918</td>\n",
       "      <td>0.527290</td>\n",
       "      <td>-0.112966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>129.833333</td>\n",
       "      <td>0.107051</td>\n",
       "      <td>0.076603</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>14.095755</td>\n",
       "      <td>6.642195</td>\n",
       "      <td>1.306952</td>\n",
       "      <td>145.658532</td>\n",
       "      <td>0.835313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2762516</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.087680</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>-0.191038</td>\n",
       "      <td>0.281778</td>\n",
       "      <td>-0.069560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>20.777778</td>\n",
       "      <td>104.222222</td>\n",
       "      <td>0.019713</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>13.854123</td>\n",
       "      <td>6.872359</td>\n",
       "      <td>0.320708</td>\n",
       "      <td>25.316333</td>\n",
       "      <td>0.353215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526403</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.072196</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>-0.139662</td>\n",
       "      <td>0.309241</td>\n",
       "      <td>-0.048029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017225</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>103.300000</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>15.087476</td>\n",
       "      <td>6.812584</td>\n",
       "      <td>0.187361</td>\n",
       "      <td>13.615546</td>\n",
       "      <td>0.241184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1359082</td>\n",
       "      <td>0.923394</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.641558</td>\n",
       "      <td>1.314132</td>\n",
       "      <td>0.802376</td>\n",
       "      <td>0.939534</td>\n",
       "      <td>1.037409</td>\n",
       "      <td>0.040774</td>\n",
       "      <td>...</td>\n",
       "      <td>21.812500</td>\n",
       "      <td>108.187500</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.016564</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>13.500782</td>\n",
       "      <td>6.276943</td>\n",
       "      <td>0.409348</td>\n",
       "      <td>48.248568</td>\n",
       "      <td>0.400993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1140892</td>\n",
       "      <td>0.230409</td>\n",
       "      <td>0.187352</td>\n",
       "      <td>0.035101</td>\n",
       "      <td>-0.160194</td>\n",
       "      <td>0.693695</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.263178</td>\n",
       "      <td>0.378977</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>...</td>\n",
       "      <td>21.375000</td>\n",
       "      <td>133.875000</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>14.008550</td>\n",
       "      <td>6.500195</td>\n",
       "      <td>0.141729</td>\n",
       "      <td>14.808883</td>\n",
       "      <td>0.225577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_id  DI_raw_diff_avg  DI_raw_diff_std  DI_raw_diff_var  \\\n",
       "0  3123252        -0.000562         0.147280         0.021691   \n",
       "1  2762516         0.000350         0.087680         0.007688   \n",
       "2   526403         0.001344         0.072196         0.005212   \n",
       "3  1359082         0.923394         0.144000         0.020736   \n",
       "4  1140892         0.230409         0.187352         0.035101   \n",
       "\n",
       "   DI_raw_diff_min  DI_raw_diff_max  DI_raw_diff_q25  DI_raw_diff_q50  \\\n",
       "0        -0.168918         0.527290        -0.112966         0.000000   \n",
       "1        -0.191038         0.281778        -0.069560         0.000000   \n",
       "2        -0.139662         0.309241        -0.048029         0.000000   \n",
       "3         0.641558         1.314132         0.802376         0.939534   \n",
       "4        -0.160194         0.693695         0.079976         0.263178   \n",
       "\n",
       "   DI_raw_diff_q75    DI_avg  ...  lead11_average_qrs_durations  \\\n",
       "0         0.000376 -0.000025  ...                     20.333333   \n",
       "1         0.034447  0.000015  ...                     20.777778   \n",
       "2         0.017225  0.000059  ...                     21.300000   \n",
       "3         1.037409  0.040774  ...                     21.812500   \n",
       "4         0.378977  0.009977  ...                     21.375000   \n",
       "\n",
       "   lead11_average_qt_interval  lead11_lf_power  lead11_hf_power  \\\n",
       "0                  129.833333         0.107051         0.076603   \n",
       "1                  104.222222         0.019713         0.012790   \n",
       "2                  103.300000         0.008862         0.008203   \n",
       "3                  108.187500         0.027494         0.016564   \n",
       "4                  133.875000         0.006901         0.005257   \n",
       "\n",
       "   lead11_vlf_power  lead11_spectral_centroid  lead11_spectral_bandwidth  \\\n",
       "0          0.002111                 14.095755                   6.642195   \n",
       "1          0.000423                 13.854123                   6.872359   \n",
       "2          0.000108                 15.087476                   6.812584   \n",
       "3          0.000418                 13.500782                   6.276943   \n",
       "4          0.000205                 14.008550                   6.500195   \n",
       "\n",
       "   lead11_spectral_entropy  lead11_average_energy  lead11_average_std  \n",
       "0                 1.306952             145.658532            0.835313  \n",
       "1                 0.320708              25.316333            0.353215  \n",
       "2                 0.187361              13.615546            0.241184  \n",
       "3                 0.409348              48.248568            0.400993  \n",
       "4                 0.141729              14.808883            0.225577  \n",
       "\n",
       "[5 rows x 1021 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, train_labels, on='exam_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_preds(preds):\n",
    "    def get_class(p):\n",
    "        return np.argmax(p)\n",
    "    int_preds = np.apply_along_axis(get_class, 1, preds)\n",
    "    return int_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['classe']\n",
    "train_columns = [col for col in train_df.columns if (col not in ['exam_id','classe'])]\n",
    "\n",
    "oof_preds = np.zeros((len(train_df), 7))\n",
    "test_preds_fold = np.zeros((len(test_df), 7))\n",
    "score_folds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "class_weight = {0:1, 1:2, 2:2, 3:2, 4:2, 5:2, 6:2}\n",
    "for value in classes:\n",
    "    weights[value] = weights[value] * class_weight[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Iteration: 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's multi_logloss: 0.0268263\tvalid_1's multi_logloss: 0.327813\n",
      "[1000]\ttraining's multi_logloss: 0.00729567\tvalid_1's multi_logloss: 0.254005\n",
      "[1500]\ttraining's multi_logloss: 0.00286937\tvalid_1's multi_logloss: 0.249147\n",
      "Early stopping, best iteration is:\n",
      "[1357]\ttraining's multi_logloss: 0.00360267\tvalid_1's multi_logloss: 0.24801\n",
      "FOLD MACRO F1 = 0.7108069154742143\n",
      "Fold: 2\n",
      "Iteration: 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's multi_logloss: 0.0272029\tvalid_1's multi_logloss: 0.31745\n",
      "[1000]\ttraining's multi_logloss: 0.0075814\tvalid_1's multi_logloss: 0.237739\n",
      "[1500]\ttraining's multi_logloss: 0.00326863\tvalid_1's multi_logloss: 0.229727\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's multi_logloss: 0.00376807\tvalid_1's multi_logloss: 0.229505\n",
      "FOLD MACRO F1 = 0.7269506519821011\n",
      "Fold: 3\n",
      "Iteration: 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's multi_logloss: 0.0273458\tvalid_1's multi_logloss: 0.321439\n",
      "[1000]\ttraining's multi_logloss: 0.00754475\tvalid_1's multi_logloss: 0.24733\n",
      "[1500]\ttraining's multi_logloss: 0.00320247\tvalid_1's multi_logloss: 0.241036\n",
      "Early stopping, best iteration is:\n",
      "[1443]\ttraining's multi_logloss: 0.0035341\tvalid_1's multi_logloss: 0.240334\n",
      "FOLD MACRO F1 = 0.721117374762872\n",
      "Fold: 4\n",
      "Iteration: 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's multi_logloss: 0.0271118\tvalid_1's multi_logloss: 0.31714\n",
      "[1000]\ttraining's multi_logloss: 0.00769247\tvalid_1's multi_logloss: 0.248008\n",
      "[1500]\ttraining's multi_logloss: 0.00321304\tvalid_1's multi_logloss: 0.240939\n",
      "Early stopping, best iteration is:\n",
      "[1424]\ttraining's multi_logloss: 0.00355061\tvalid_1's multi_logloss: 0.240387\n",
      "FOLD MACRO F1 = 0.7195400382608126\n",
      "Fold: 5\n",
      "Iteration: 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's multi_logloss: 0.0276152\tvalid_1's multi_logloss: 0.347591\n",
      "[1000]\ttraining's multi_logloss: 0.0072279\tvalid_1's multi_logloss: 0.264453\n",
      "[1500]\ttraining's multi_logloss: 0.00305341\tvalid_1's multi_logloss: 0.259519\n",
      "Early stopping, best iteration is:\n",
      "[1323]\ttraining's multi_logloss: 0.00389874\tvalid_1's multi_logloss: 0.258334\n",
      "FOLD MACRO F1 = 0.7149815378592713\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "folds = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    print(\"Fold: {}\".format(fold_+1))\n",
    "\n",
    "    trn_x, trn_y = train_df.loc[trn_, train_columns], y.loc[trn_]\n",
    "    val_x, val_y = train_df.loc[val_, train_columns], y.loc[val_]\n",
    "    \n",
    "    w = trn_y.map(weights) #* train_seq_len.loc[trn_, 'nw']\n",
    "    dtrain = lgb.Dataset(trn_x, trn_y, weight=w)\n",
    "    dvalid = lgb.Dataset(val_x, val_y)\n",
    "  \n",
    "    params = {\n",
    "        'boost': 'gbdt',\n",
    "        'num_class': 7,\n",
    "        'max_depth': -1,\n",
    "        'num_leaves': 10,\n",
    "        'objective': 'multiclass',\n",
    "        'min_data_in_leaf': 15,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 10,\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_threads': -1,\n",
    "        'verbosity': -1,\n",
    "        'seed': 159\n",
    "    }\n",
    "    \n",
    "    execs = 1\n",
    "    preds = np.zeros((len(val_x), 7))\n",
    "    test_preds_exec = np.zeros((len(test_df), 7))\n",
    "\n",
    "    early_stop_cb = early_stopping(stopping_rounds=200)\n",
    "    log_eval_cb = log_evaluation(period=500)\n",
    "\n",
    "    \n",
    "    for p in range(0,execs):\n",
    "        print(\"Iteration: {}\".format(p+1))\n",
    "        params['seed'] += p\n",
    "        model = lgb.train(params,\n",
    "                        dtrain,\n",
    "                        num_boost_round = 100000,\n",
    "                        valid_sets = [dtrain, dvalid],\n",
    "                        callbacks=[early_stop_cb, log_eval_cb])\n",
    "        \n",
    "        preds += ((model.predict(val_x)) / execs)\n",
    "        test_preds_exec += ((model.predict(test_df[train_columns])) / execs)\n",
    "        \n",
    "    #lgb.plot_importance(model, importance_type='split', max_num_features=30)\n",
    "    #lgb.plot_importance(model, importance_type='gain', max_num_features=20)\n",
    "\n",
    "    test_preds_fold += (test_preds_exec / n_folds)\n",
    "    oof_preds[val_] = preds\n",
    "    oof_int_preds = get_integer_preds(preds)\n",
    "    test_int_preds = get_integer_preds(test_preds_exec)\n",
    "    score_folds.append(f1_score(val_y, oof_int_preds, average='macro'))\n",
    "    print(\"FOLD MACRO F1 = {}\".format(f1_score(val_y, oof_int_preds, average='macro')))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN MACRO F1 = 0.7186793036678542\n",
      "OOF MACRO F1 = 0.7187284495402017\n",
      "[0.7108069154742143, 0.7269506519821011, 0.721117374762872, 0.7195400382608126, 0.7149815378592713]\n"
     ]
    }
   ],
   "source": [
    "print(\"MEAN MACRO F1 = {}\".format(np.mean(score_folds)))\n",
    "print(\"OOF MACRO F1 = {}\".format(f1_score(y, get_integer_preds(oof_preds), average='macro')))\n",
    "print(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'exam_id': test_df.exam_id, 'classe': get_integer_preds(test_preds_fold)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.set_index('exam_id')\n",
    "train_labels = pd.read_csv('./input/train_dccweek2023-labels.csv', index_col='exam_id')\n",
    "both = [i for i in train_labels.index if i in sub.index]\n",
    "sub.loc[both, 'classe'] = train_labels['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_probs = pd.DataFrame(test_preds_fold, columns=['class_' + str(s) for s in range(7)])\n",
    "sub_probs['exam_id'] = test_df.exam_id\n",
    "sub_probs.to_csv('./output/lgb_v2000_probs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./output/lgb_v2000_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
